---
output: html_document
---

## Some distributions

First of all, let's pinpoint some definitions:

#### Expected Value

Let $X$ be a numerically-valued discrete random variable with sample space
$\Omega$ and distribution function $m(x)$. The _expected value_ $E(X)$ is defined by

$$E(X) = \sum _{x \in \Omega} {x ~ m(x)}$$

provided this sum converged absolutely. We often refer to the expected value as the _mean_, and denote $E(X)$ by $\mu$ for short. If the above sum does not converge absolutely, then we say that $X$ does not have and expected value.

#### Variance and Standard Deviation

Let $X$ be a numerically valued random variable with expected value
$\mu = E(X)$. Then the _variance_ of $X$, denoted by $V (X)$, is

$$V (X) = E((X - \mu)^2) = \sum _{x} {(x - \mu)^2 ~ m(x)}$$

where $m$ is the distribution function of $X$.

The *standard deviation* of $X$, denoted by $D(X)$, is $D(X) = \sqrt {V(X)}$. We often write $\sigma$ for $D(X)$ and $\sigma^2$ for $V(X)$.

---

## Experiments and Distributions

Let's try simulating lots of averages from various distributions and showing
that the resulting distribution looks like a bell curve.

### Dice rolling

$$\mu = \sum _{x \in \lbrace 1..6 \rbrace} {x ~ m(x)} = 1 \big(\frac{1}{6} \big) + 2 \big(\frac{1}{6} \big) + 3 \big(\frac{1}{6} \big) + 4 \big(\frac{1}{6} \big) + 5 \big(\frac{1}{6} \big) + 6 \big(\frac{1}{6} \big) = \frac{7}{2} = 3.5$$

 $x$ | $m(x)$ |   | $x m(x)$ | $(x-\mu)^2$ | $(x-\mu)^2 m(x)$
--- | ------ | --- | -------- | --------- | --------------
 1 |  1/6 |   |   1/6  |   25/4  |    25/24
 2 |  1/6 |   |   1/3  |    9/4  |     3/8
 3 |  1/6 |   |   1/2  |    1/4  |     1/24
 4 |  1/6 |   |   2/3  |    1/4  |     1/24
 5 |  1/6 |   |   5/6  |    9/4  |     3/8
 6 |  1/6 |   |    1   |   25/4  |    25/24
--- |------ | --- | -------- | --------- | --------------
   | $\mu =$ |   | 7/2 | $\sigma^2 =$ | 35/12


* $\mu = E(X) = \frac {1}{6} \sum _{i=1} ^{6} x_i = 7 / 2 = 3.5$  
* $\sigma^2 = V(X) = 35/12$  
* $\sigma = D(X) = \sqrt {V(X)} = \sqrt {35/12} \approx 1.707$

### Two dice rolling

$$\mu = 2 \big(\frac{1}{36} \big) + 3 \big(\frac{1}{18} \big) + 4 \big(\frac{1}{12} \big) + 5 \big(\frac{1}{9} \big) + 6 \big(\frac{5}{36} \big) + 7 \big(\frac{1}{6} \big) + 8 \big(\frac{5}{36} \big) + 9 \big(\frac{1}{9} \big) + 10 \big(\frac{1}{12} \big) + 11 \big(\frac{1}{18} \big) + 12 \big(\frac{1}{36} \big) = 7$$

 $x$ | $m(x)$ |   | $x m(x)$ | $(x-\mu)^2$ | $(x-\mu)^2 m(x)$
--- | ------ | --- | -------- | --------- | --------------
 2 | 1/36 |   |   1/18 |    25   |    25/36
 3 | 1/18 |   |   1/6  |    16   |     8/9
 4 | 1/12 |   |   1/3  |     9   |     3/4
 5 |  1/9 |   |   5/9  |     4   |     4/9
 6 | 5/36 |   |   5/6  |     1   |     5/36
 7 |  1/6 |   |   7/6  |     0   |     0
 8 | 5/36 |   |  10/9  |     1   |     5/36
 9 |  1/9 |   |    1   |     4   |     4/9
10 | 1/12 |   |   5/6  |     9   |     3/4
11 | 1/18 |   |  11/18 |    16   |     8/9
12 | 1/36 |   |   1/3  |    25   |    25/36
--- | ------ | --- | -------- | --------- | --------------
   | $\mu =$ |    |  7 | $\sigma^2 =$ | 35/6


* $\mu = E(X) = 7$  
* $\sigma^2 = V(x) = 35 / 6$  
* $\sigma = D(X) = \sqrt {V(X)} = \sqrt {35 / 6} \approx 2.415$

### Coin flip (Bernoulli distribution)

The Bernoulli distribution is the probability distribution of a random variable which takes value $1$ with success probability $p$ and value $0$ with failure probability $q = 1 - p$. It can be used, for example, to represent the toss of a coin, where "1" is defined to mean "heads" and "0" is defined to mean "tails" (or vice versa).[(*)](http://en.wikipedia.org/wiki/Bernoulli_distribution)

* $\mu = E(X) = p$  
* $\sigma^2 = V(X) = p(1 - p)$
* $\sigma = D(X) = \sqrt {\sigma^2} = \sqrt {p(1 - p)}$

For $p = 0.5$  
$\mu = 0.5, \sigma^2 = 0.5(1 - 0.5) = 0.25, \sigma = \sqrt {\sigma^2} = 0.5$


### Exponential distribution

The Exponential distribution is the probability distribution that describes the time between events in a Poisson process, i.e. a process in which events occur continuously and independently at a constant average rate.[(*)](http://en.wikipedia.org/wiki/Exponential_distribution)
Some examples of events which can be analyzed with exponential distributions are the time until a radioactive particle decays, or the time between clicks of a geiger counter, 
the time it takes before your next telephone call, and
the time until default (on payment to company debt holders) in reduced form credit risk modeling

Here $\lambda > 0$ is the parameter of the distribution, often called the _rate parameter_;

* $\mu = E(X) = 1 / \lambda$  
* $\sigma^2 = V(X) = 1 / \lambda^2$
* $\sigma = D(X) = \sqrt {\sigma^2} = \sqrt {1 / \lambda^2} = 1 / \lambda$


### Poisson distribution

The Poisson distribution expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event.[(*)](http://en.wikipedia.org/wiki/Poisson_distribution)
The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.

The positive real number $\lambda$ is equal to the expected value of X and also to its variance:

* $\mu = E(X)= \lambda$  
* $\sigma^2 = V(X) = \lambda$  
* $\sigma = D(X) = \sqrt {\sigma^2} = \sqrt {\lambda}$

--------


-------
