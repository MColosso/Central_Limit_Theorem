---
output: html_document
---

## Definition (cont.)

For our purposes, the **Central Limit Theorem** (CLT) states that the distribution of averages of independent and identically distributed random variables
[(iid variables)](http://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)
becomes that of a standard normal as the sample size increases. Consider this
fact for a second. We already know the mean and standard deviation of the
distribution of averages from _**iid**_ samples. The CLT gives us an
approximation to the full distribution!
Thus, for _**iid**_ samples, we have a good sense of distribution of the average event though: (1) we only observed one average and (2) we don't know
what the population distribution is. Because of this, the CLT applies in an
endless variety of settings and is one of the most important theorems ever
discovered.

More formally:

- Let $X_1,\ldots,X_n$ be a collection of iid random variables with mean $\mu$ and variance $\sigma^2$
- Let $\bar X_n$ be their sample average
- Then 

$$
\frac{\bar X_n - \mu}{\sigma / \sqrt{n}}=
\frac{\sqrt n (\bar X_n - \mu)}{\sigma}
= \frac{\mbox{Estimate} - \mbox{Mean of estimate}}{\mbox{Std. Err. of estimate}}
$$

has a distribution like that of a standard normal for large $n$.
Replacing the standard error by its estimated value doesn't change the CLT.

The useful way to think about the CLT is that $\bar X_n$
is approximately $N(\mu, \sigma^2 / n)$.
